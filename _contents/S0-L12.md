---
layout: post
title: LLM multimodal harm responses  
lecture: S0-Intro
lectureVersion: next
extraContent: 
notes: team-1
video:  team-2
tags:
- 1Basic
---

In this session, our readings cover: 

## Readings: 
  ### Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned
  - https://arxiv.org/abs/2209.07858

  ### Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!
  + https://arxiv.org/abs/2310.03693

  ### GOAT-Bench: Safety Insights to Large Multimodal Models through Meme-Based Social Abuse
  + https://arxiv.org/abs/2401.01523

  ### Misusing Tools in Large Language Models With Visual Adversarial Examples
  + https://arxiv.org/abs/2310.03185

  




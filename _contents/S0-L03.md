---
layout: post
title: LLM evaluating framework
lecture: 
lectureVersion: next
extraContent: 
notes: team-1
video:  team-5
tags:
- 1Basic
---

In this session, our readings cover: 



## Required Readings: 



### Holistic Evaluation of Text-To-Image Models
  + https://arxiv.org/abs/2311.04287
  + The stunning qualitative improvement of recent text-to-image models has led to their widespread attention and adoption. However, we lack a comprehensive quantitative understanding of their capabilities and risks. To fill this gap, we introduce a new benchmark, Holistic Evaluation of Text-to-Image Models (HEIM). Whereas previous evaluations focus mostly on text-image alignment and image quality, we identify 12 aspects, including text-image alignment, image quality, aesthetics, originality, reasoning, knowledge, bias, toxicity, fairness, robustness, multilinguality, and efficiency. We curate 62 scenarios encompassing these aspects and evaluate 26 state-of-the-art text-to-image models on this benchmark. Our results reveal that no single model excels in all aspects, with different models demonstrating different strengths. We release the generated images and human evaluation results for full transparency at this https URL and the code at this https URL, which is integrated with the HELM codebase.


### Holistic Evaluation of Language Models
  + https://arxiv.org/abs/2211.09110 


## More Readings: 


### Evaluating Large Language Models: A Comprehensive Survey
  + https://arxiv.org/abs/2310.19736


### Evaluating Large Language Models Trained on Code
  + https://arxiv.org/abs/2107.03374

### chatbot-arena-leaderboard
  + https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard



---
layout: post
title: FM's X risk 
lecture: S0-Intro
lectureVersion: next
extraContent: 
notes: team-5
video: team-3
tags:
- 1Basic
---

In this session, our readings cover: 

## Required Readings: 

### Managing Existential Risk from AI without Undercutting Innovation
  + https://www.csis.org/analysis/managing-existential-risk-ai-without-undercutting-innovation

### OpenAI on LLM generated bio-x-risk
+ Building an early warning system for LLM-aided biological threat creation
+ https://openai.com/research/building-an-early-warning-system-for-llm-aided-biological-threat-creation

## More Readings: 

### A misleading open letter about sci-fi AI dangers ignores the real risks
  https://www.aisnakeoil.com/p/a-misleading-open-letter-about-sci

### Evaluating social and ethical risks from generative AI
  + https://deepmind.google/discover/blog/evaluating-social-and-ethical-risks-from-generative-ai/

### Emergent autonomous scientific research capabilities of large language models
  + https://arxiv.org/abs/2304.05332
  + Transformer-based large language models are rapidly advancing in the field of machine learning research, with applications spanning natural language, biology, chemistry, and computer programming. Extreme scaling and reinforcement learning from human feedback have significantly improved the quality of generated text, enabling these models to perform various tasks and reason about their choices. In this paper, we present an Intelligent Agent system that combines multiple large language models for autonomous design, planning, and execution of scientific experiments. We showcase the Agent's scientific research capabilities with three distinct examples, with the most complex being the successful performance of catalyzed cross-coupling reactions. Finally, we discuss the safety implications of such systems and propose measures to prevent their misuse.


### On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?
  + https://dl.acm.org/doi/10.1145/3442188.3445922

